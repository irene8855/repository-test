import os
import time
import requests
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
import pickle
from datetime import datetime

# --- –°–µ–∫—Ä–µ—Ç—ã ---
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")
POLYGON_API_URL = os.getenv("POLYGON_API_URL")  # –ù–∞–ø—Ä–∏–º–µ—Ä https://polygon-mainnet.g.alchemy.com/v2/your-api-key

# --- –ê–¥—Ä–µ—Å–∞ —Ç–æ–∫–µ–Ω–æ–≤ (Polygon) ---
TOKENS = {
    "LDO": "0xc3c7d422809852031b44ab29eec9f1eff2a58756",
    "SAND": "0xbbba073c31bf03b8acf7c28ef0738decf3695683",
    "GMT": "0xe3c408bd53c31c085a1746af401a4042954ff740",
    "FRAX": "0x45c32fa6df82ead1e2ef74d17b76547eddfaff89",
    "LINK": "0x53e0bca35ec356bd5dddfebbd1fc0fd03fabad39",
    "SUSHI": "0x0b3f868e0be5597d5db7feb59e1cadbb0fdda50a",
    "wstETH": "0x7ceb23fd6bc0add59e62ac25578270cff1b9f619",
    "AAVE": "0xd6df932a45c0f255f85145f286ea0b292b21c90b",
    "MATIC": "0x7d1afa7b718fb893db30a3abc0cfc608aacfebb0",
    "UNI": "0x1f9840a85d5af5bf1d1762f925bdaddc4201f984",
    "MKR": "0x9f8f72aa9304c8b593d555f12ef6589cc3a579a2"
}

# --- –ü–∞—Ä—ã –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ (–Ω–∞–∑–≤–∞–Ω–∏–µ: [–∞–¥—Ä–µ—Å —Ç–æ–∫–µ–Ω–∞]) ---
PAIRS = {
    "LDOUSDT": TOKENS["LDO"],
    "SANDUSDT": TOKENS["SAND"],
    "GMTUSDT": TOKENS["GMT"],
    "FRAXUSDT": TOKENS["FRAX"],
    "LINKUSDT": TOKENS["LINK"],
    "SUSHIUSDT": TOKENS["SUSHI"],
    "wstETHUSDT": TOKENS["wstETH"],
    "AAVEUSDT": TOKENS["AAVE"],
    "MATICUSDT": TOKENS["MATIC"],
    "UNIUSDT": TOKENS["UNI"],
    "MKRUSDT": TOKENS["MKR"],
}

# --- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—É—Å–∫–∞ ---
print("‚úÖ main.py —Å—Ç–∞—Ä—Ç–æ–≤–∞–ª")
print("‚úÖ TELEGRAM_TOKEN –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç:", TELEGRAM_TOKEN[:5] + "..." if TELEGRAM_TOKEN else "‚ùå –ù–ï–¢")
print("‚úÖ TELEGRAM_CHAT_ID –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç:", TELEGRAM_CHAT_ID if TELEGRAM_CHAT_ID else "‚ùå –ù–ï–¢")
print("‚úÖ POLYGON_API_URL –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç:", POLYGON_API_URL[:10] + "..." if POLYGON_API_URL else "‚ùå –ù–ï–¢")

# --- –§—É–Ω–∫—Ü–∏—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ Telegram ---
def send_telegram_message(text: str):
    if not TELEGRAM_TOKEN or not TELEGRAM_CHAT_ID:
        print("‚ùå Telegram token –∏–ª–∏ chat_id –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –Ω–µ –º–æ–≥—É –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ")
        return
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    data = {"chat_id": TELEGRAM_CHAT_ID, "text": text}
    try:
        r = requests.post(url, data=data, timeout=10)
        if r.status_code == 200:
            print(f"‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ Telegram: {text}")
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram: {r.status_code} {r.text}")
    except Exception as e:
        print(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –≤ Telegram: {e}")

# --- –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å—Ç–∞—Ä—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ ---
send_telegram_message("üöÄ –ë–æ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏ –ø—Ä–æ–≥–Ω–æ–∑–∞ –∑–∞–ø—É—â–µ–Ω")

# --- –ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ —Ü–µ–Ω–µ —Ç–æ–∫–µ–Ω–∞ —Å Polygon API ---
def fetch_historical_prices(token_address, limit=200):
    """
    –ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–¥–µ–ª–∫–∏ –¥–ª—è —Ç–æ–∫–µ–Ω–∞ —Å Polygon API
    """
    url = f"{POLYGON_API_URL}/v2/aggs/ticker/{token_address}/range/1/minute/{int(time.time()-limit*60)}/{int(time.time())}"
    try:
        response = requests.get(url, timeout=10)
        if response.status_code != 200:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {response.status_code}")
            return None
        data = response.json()
        if 'results' not in data:
            print("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ –æ—Ç–≤–µ—Ç–µ –æ—Ç Polygon")
            return None
        df = pd.DataFrame(data['results'])
        # –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: c - close, o - open, h - high, l - low, v - volume
        df = df.rename(columns={"c": "close", "o": "open", "h": "high", "l": "low", "v": "volume"})
        df['t'] = pd.to_datetime(df['t'], unit='ms')
        df.set_index('t', inplace=True)
        return df[['open', 'high', 'low', 'close', 'volume']]
    except Exception as e:
        print(f"–ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
        return None

# --- –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ ---
def train_model(df: pd.DataFrame):
    """
    –û–±—É—á–∏—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö.
    –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã ‚Äî –±—É–¥–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å, –≤—ã—Ä–∞—Å—Ç–µ—Ç –ª–∏ —Ü–µ–Ω–∞ —á–µ—Ä–µ–∑ 5 –º–∏–Ω—É—Ç –Ω–∞ 0.5% –∏ –±–æ–ª–µ–µ.
    """
    df = df.copy()
    df['future_close'] = df['close'].shift(-5)
    df['target'] = (df['future_close'] / df['close'] - 1) >= 0.005  # 0.5% —Ä–æ—Å—Ç —á–µ—Ä–µ–∑ 5 –º–∏–Ω—É—Ç
    df.dropna(inplace=True)

    features = ['open', 'high', 'low', 'close', 'volume']
    X = df[features]
    y = df['target'].astype(int)

    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X, y)
    print("‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞")
    return model

# --- –§—É–Ω–∫—Ü–∏—è –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π ---
def monitor_and_predict():
    model_store = {}

    while True:
        for pair_name, token_addr in PAIRS.items():
            print(f"üîÑ –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è {pair_name}")
            df = fetch_historical_prices(token_addr)
            if df is None or len(df) < 50:
                print(f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {pair_name}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue

            # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ –¥–∞–Ω–Ω—ã—Ö
            model = train_model(df)

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            latest = df.iloc[-1][['open', 'high', 'low', 'close', 'volume']].values.reshape(1, -1)
            pred_prob = model.predict_proba(latest)[0][1]
            pred_label = model.predict(latest)[0]

            print(f"‚ÑπÔ∏è –ü—Ä–æ–≥–Ω–æ–∑ –¥–ª—è {pair_name}: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–æ—Å—Ç–∞ {pred_prob:.2f}, –º–µ—Ç–∫–∞ {pred_label}")

            # –ï—Å–ª–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤—ã—Å–æ–∫–∞—è, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            if pred_prob > 0.7:
                send_telegram_message(f"üîÆ Predictive —Å–∏–≥–Ω–∞–ª –ø–æ {pair_name}: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–æ—Å—Ç–∞ {pred_prob:.2%}")

                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –∂–¥–µ–º –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —á–µ—Ä–µ–∑ 5 –º–∏–Ω—É—Ç
                time.sleep(300)  # 5 –º–∏–Ω—É—Ç
                df_confirm = fetch_historical_prices(token_addr)
                if df_confirm is None or len(df_confirm) < 50:
                    print(f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è {pair_name}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    continue
                last_close = df.iloc[-1]['close']
                confirm_close = df_confirm.iloc[-1]['close']
                growth = (confirm_close / last_close - 1) * 100

                if growth >= 0.5:
                    send_telegram_message(f"‚úÖ Confirmed —Å–∏–≥–Ω–∞–ª –ø–æ {pair_name}: —Ä–æ—Å—Ç +{growth:.2f}% –∑–∞ 5 –º–∏–Ω—É—Ç")
                else:
                    send_telegram_message(f"‚ùå Confirmed —Å–∏–≥–Ω–∞–ª –ø–æ {pair_name} –ù–ï –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª—Å—è: —Ä–æ—Å—Ç {growth:.2f}%")
            else:
                print(f"‚ÑπÔ∏è –ù–µ—Ç —Å–∏–ª—å–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ –ø–æ {pair_name}")

            time.sleep(5)  # –Ω–µ–±–æ–ª—å—à–æ–π —Ç–∞–π–º–∞—É—Ç –º–µ–∂–¥—É –ø–∞—Ä–∞–º–∏

        print("‚è≥ –¶–∏–∫–ª –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∑–∞–≤–µ—Ä—à—ë–Ω, –Ω–∞—á–∏–Ω–∞–µ–º –∑–∞–Ω–æ–≤–æ —á–µ—Ä–µ–∑ 1 –º–∏–Ω—É—Ç—É")
        time.sleep(60)


if __name__ == "__main__":
    try:
        monitor_and_predict()
    except KeyboardInterrupt:
        print("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–æ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ä–∞–±–æ—Ç–µ –±–æ—Ç–∞: {e}")
        
